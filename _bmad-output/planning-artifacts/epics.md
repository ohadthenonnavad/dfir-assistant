# Epics and Stories Document
# Windows Internals DFIR Knowledge Assistant

---
workflowStep: 4
status: 'complete'
extractedAt: '2026-01-15'
designedAt: '2026-01-15'
storiesCreatedAt: '2026-01-15'
validatedAt: '2026-01-15'
storiesDocument: stories.md
sourceDocuments:
  - _bmad-output/planning-artifacts/prd-windows-dfir-assistant-v2.md
  - _bmad-output/planning-artifacts/architecture.md
totalStoryPoints: 124
epicCount: 11
---

## Step 1: Requirements Extraction Summary

This document consolidates all requirements extracted from the PRD v2.0 and Architecture documents for epic/story creation.

---

## Functional Requirements (FRs)

### FR-001: Knowledge Q&A
**Priority:** P0 (Must Have)

| Aspect | Details |
|--------|---------|
| **Description** | Answer questions about Windows internals, memory forensics, forensic artifacts, attack techniques, and tool usage |
| **Query Types** | Processes, threads, memory, registry, VAD analysis, injection detection, rootkits, persistence, Volatility 3 |
| **Architectural Complexity** | Medium - Standard RAG |

**Acceptance Criteria:**
- [ ] Responds to natural language questions
- [ ] Retrieves relevant chunks from knowledge base
- [ ] Generates structured, educational responses
- [ ] Cites source material when available

---

### FR-002: Anomaly Explanation
**Priority:** P0 (Must Have)

| Aspect | Details |
|--------|---------|
| **Description** | Explain anomalies with technical meaning, legitimate vs malicious comparison, triage commands, correlation steps |
| **Output Elements** | Technical explanation, comparison table, Volatility commands, decision tree |
| **Architectural Complexity** | High - Structured output with tables |

**Acceptance Criteria:**
- [ ] Recognizes anomaly description patterns
- [ ] Generates structured anomaly response template
- [ ] Includes exact, validated Volatility commands
- [ ] Provides decision tree for severity classification

---

### FR-003: Procedural Guidance
**Priority:** P0 (Must Have)

| Aspect | Details |
|--------|---------|
| **Description** | Step-by-step procedures for memory forensics, registry analysis, process analysis, persistence detection, IOC extraction |
| **Output Format** | Numbered steps, exact commands, output interpretation, next steps |
| **Architectural Complexity** | High - Command validation required |

**Acceptance Criteria:**
- [ ] Numbered steps with exact commands
- [ ] Explanation of what each step accomplishes
- [ ] Expected output interpretation
- [ ] Next steps based on findings

---

### FR-004: Organization-Aware Responses
**Priority:** P1 (Should Have)

| Aspect | Details |
|--------|---------|
| **Description** | Incorporate organization-specific context: tools/versions, SOPs, escalation procedures, common findings |
| **Customization** | Team tools, internal tool names, escalation triggers, org workflows |
| **Architectural Complexity** | Medium - Additional retrieval source |

**Acceptance Criteria:**
- [ ] Responses reference org-specific tools
- [ ] Includes escalation triggers (e.g., "escalate to senior if rootkit")
- [ ] Follows org investigation workflow
- [ ] Uses internal tool names and syntax

---

### FR-005: Multi-Turn Conversations
**Priority:** P1 (Should Have)

| Aspect | Details |
|--------|---------|
| **Description** | Maintain context across conversation turns, handle follow-ups, track investigation state |
| **Session Features** | Context reference, state tracking, summarization on request |
| **Architectural Complexity** | Medium - Session state management |

**Acceptance Criteria:**
- [ ] Understands "what about X?" follow-ups
- [ ] Tracks what's already been covered
- [ ] Summarizes current investigation state on request

---

## Non-Functional Requirements (NFRs)

### NFR-PERF: Performance Requirements

| Metric | Target | Architectural Support |
|--------|--------|----------------------|
| **Response Latency** | <10s first token | Streaming, GPU LLM |
| **Full Response Time** | <30s typical | Optimized retrieval |
| **Embedding Latency** | <500ms per query | nomic-embed-text |
| **Retrieval Latency** | <200ms | Qdrant search |

---

### NFR-SEC: Security Requirements

| Requirement | Details | Architectural Support |
|-------------|---------|----------------------|
| **Air-Gap Deployment** | All components run locally, no internet | 100% local deployment |
| **Data Residency** | All data stays on local system | Local file storage |
| **No Telemetry** | No data sent to external services | No cloud dependencies |
| **Audit Logging** | Log queries and responses for review | Append-only logs |

---

### NFR-SCALE: Scalability Requirements

| Scenario | Requirement | Architectural Support |
|----------|-------------|----------------------|
| **Concurrent Users** | Single user (MVP); plan for 3-5 | Shared Qdrant/Ollama |
| **Knowledge Base Size** | ~50K chunks from 30 books | Single Qdrant collection |
| **Conversation Length** | 20+ turn conversations | Session state management |

---

### NFR-AVAIL: Availability Requirements

| Requirement | Target | Architectural Support |
|-------------|--------|----------------------|
| **Uptime** | Business hours (not 24/7) | Systemd service |
| **Recovery** | Restart within 5 minutes | Simple restart, persistent data |
| **Data Persistence** | Survive system restart | Qdrant persistence |

---

### NFR-VRAM: VRAM Budget Requirements

| Component | VRAM | Location |
|-----------|------|----------|
| Qwen2.5 32B Q4_K_M | 18-20GB | GPU |
| nomic-embed-text | 0 | CPU (conservative) |
| Qdrant indexes | 0 | System RAM |
| System overhead | 2-4GB | GPU |
| **Available Headroom** | **2-4GB** | Buffer |

---

### NFR-TRUST: Trust Requirements

| Requirement | Target | Implementation |
|-------------|--------|----------------|
| **Command Accuracy** | 100% valid Volatility commands | Post-generation validation |
| **Confidence Scoring** | High/Medium/Low | Multi-factor scoring |
| **Explicit Uncertainty** | Admit when unknown | "I don't know" responses |
| **Source Citations** | Every response | Book + chapter attribution |

---

## Data Requirements

### DR-001: Knowledge Base Sources

| Source Type | Examples | Priority |
|-------------|----------|----------|
| **Technical Books** | Windows Internals 7th Ed, Art of Memory Forensics | P0 |
| **Tool Documentation** | Volatility 3 plugin reference | P0 |
| **Organization Docs** | SOPs, playbooks, tool guides | P1 |
| **Threat Intelligence** | MITRE ATT&CK Windows techniques | P1 |

### DR-002: Data Format Requirements

- PDF books (10-100MB each, complex layouts)
- Markdown documentation
- YAML/JSON configuration files
- Text-based command references

---

## Technical Constraints (from Architecture)

| Constraint | Impact | Mitigation |
|------------|--------|------------|
| **Air-Gap Deployment** | All models must run locally; no cloud | uv lock files, offline deps |
| **24GB VRAM Limit** | Limits model size to ~32B quantized | Conservative VRAM allocation |
| **Single GPU** | No model parallelism; batch size limited | Sequential inference |
| **PDF Complexity** | Complex layouts, code, tables | marker-pdf + validation |
| **Copyright** | User-provided books | No content distribution |

---

## Cross-Cutting Concerns (from Architecture)

1. **VRAM Management** (ğŸ”´ BLOCKING) - Must validate empirically before development
2. **Command Validation** - Every Volatility command validated against plugin list
3. **Retrieval Quality** - Confidence scoring, "I don't know" responses
4. **Response Structuring** - Instructor/Pydantic for consistent output
5. **Audit Logging** - All queries and responses logged
6. **Source Citations** - Every response cites source material
7. **Testability** - Mocking strategy for air-gap CI

---

## Architectural Decisions Impact on Stories

### Decision 1: Conservative VRAM Allocation
- Embedding model on CPU
- Stories must validate VRAM usage before feature work

### Decision 2: Hybrid Chunking with Semantic Boundaries
- Never split code blocks, tables, command sequences
- Stories must respect 512 token chunks with 100 overlap

### Decision 3: Adaptive Search Weights
- Query classifier determines dense/sparse weights
- Stories must implement query analysis component

### Decision 4: Pydantic Settings Configuration
- Type-safe defaults with YAML override
- Stories must use Settings class for configuration

### Decision 5: Explicit Uncertainty Error Handling
- Trust > Utility > Experience priority
- Stories must implement confidence scoring and disclaimers

---

## PRD Epics (Pre-defined in PRD v2.0)

### Critical Review Epics (Risk Mitigation)

| Epic | Description | Points | Priority |
|------|-------------|--------|----------|
| **EPIC-001** | VRAM Validation & Fallback Planning | 8 | ğŸ”´ BLOCKING |
| **EPIC-002** | Command Validation Safety Layer | 8 | P0 |
| **EPIC-003** | Evaluation Framework | 13 | P0 |
| **EPIC-004** | Organization Context Maintenance | 5 | P1 |
| **EPIC-005** | Retrieval Failure Handling | 8 | P0 |
| **EPIC-006** | PDF Processing Quality | 8 | P1 |
| **EPIC-007** | Single Collection Architecture | 5 | P1 |
| **Subtotal** | | **55** | |

### Feature Development Epics

| Epic | Description | Points | Priority |
|------|-------------|--------|----------|
| **EPIC-100** | Data Ingestion Pipeline | 21 | P0 |
| **EPIC-101** | RAG Pipeline | 13 | P0 |
| **EPIC-102** | Response Generation | 24 | P0 |
| **EPIC-103** | User Interface | 11 | P1 |
| **Subtotal** | | **69** | |

**GRAND TOTAL: 124 Story Points**

---

## Story Summary from PRD

### EPIC-001: VRAM Validation (8 pts) - ğŸ”´ BLOCKING

| Story ID | Story | Points |
|----------|-------|--------|
| CR-001 | Validate VRAM usage empirically | 3 |
| CR-002 | Fallback LLM option ready | 3 |
| CR-003 | VRAM monitoring in application | 2 |

### EPIC-002: Command Validation (8 pts)

| Story ID | Story | Points |
|----------|-------|--------|
| CR-004 | Volatility 3 plugin validation list | 3 |
| CR-005 | Post-generation command validation | 3 |
| CR-006 | Warnings for unverified commands | 2 |

### EPIC-003: Evaluation Framework (13 pts)

| Story ID | Story | Points |
|----------|-------|--------|
| CR-007 | Golden Q&A test dataset | 5 |
| CR-008 | Retrieval quality metrics | 3 |
| CR-009 | Response quality metrics | 3 |
| CR-010 | Regression testing on changes | 2 |

### EPIC-004: Org Context Maintenance (5 pts)

| Story ID | Story | Points |
|----------|-------|--------|
| CR-011 | Ownership for org context docs | 2 |
| CR-012 | Display last_updated in responses | 2 |
| CR-013 | User feedback to flag stale context | 1 |

### EPIC-005: Retrieval Failure Handling (8 pts)

| Story ID | Story | Points |
|----------|-------|--------|
| CR-014 | Confidence scoring on retrieval | 3 |
| CR-015 | Admit when doesn't know | 3 |
| CR-016 | Log queries with poor retrieval | 2 |

### EPIC-006: PDF Processing Quality (8 pts)

| Story ID | Story | Points |
|----------|-------|--------|
| CR-017 | Validate marker-pdf on actual books | 3 |
| CR-018 | Fallback extraction methods | 3 |
| CR-019 | Chunk quality validation | 2 |

### EPIC-007: Single Collection Architecture (5 pts)

| Story ID | Story | Points |
|----------|-------|--------|
| CR-020 | Single unified collection with metadata | 3 |
| CR-021 | Benchmark multi-collection if needed | 2 |

### EPIC-100: Data Ingestion Pipeline (21 pts)

| Story ID | Story | Points |
|----------|-------|--------|
| FD-001 | Process PDF books to markdown | 5 |
| FD-002 | Hierarchical chunking by section | 5 |
| FD-003 | Contextual retrieval prepending | 3 |
| FD-004 | Embedding generation | 3 |
| FD-005 | Qdrant index building | 5 |

### EPIC-101: RAG Pipeline (13 pts)

| Story ID | Story | Points |
|----------|-------|--------|
| FD-010 | Query embedding generation | 2 |
| FD-011 | Hybrid search vector + BM25 | 5 |
| FD-012 | Reranking with BGE-reranker | 3 |
| FD-013 | Context building for LLM | 3 |

### EPIC-102: Response Generation (24 pts)

| Story ID | Story | Points |
|----------|-------|--------|
| FD-020 | LLM client with Ollama | 3 |
| FD-021 | Instructor integration | 5 |
| FD-022 | Query intent classification | 5 |
| FD-023 | AnomalyResponse template | 5 |
| FD-024 | ConceptResponse template | 3 |
| FD-025 | ProcedureResponse template | 3 |

### EPIC-103: User Interface (11 pts)

| Story ID | Story | Points |
|----------|-------|--------|
| FD-030 | Chat interface | 3 |
| FD-031 | Streaming responses | 3 |
| FD-032 | Source citations display | 3 |
| FD-033 | Response feedback | 2 |

---

## Success Metrics (from PRD)

| Metric | Target | How Measured |
|--------|--------|--------------|
| **Retrieval Accuracy** | >80% Recall@5 | Automated eval against golden dataset |
| **Response Quality** | >90% contain required elements | Human review of sample responses |
| **Command Accuracy** | 100% valid Volatility commands | Automated validation against plugin list |
| **User Satisfaction** | >4.0/5.0 helpfulness rating | Post-response feedback collection |
| **Time Savings** | 30% reduction in time-to-first-finding | A/B comparison with control group |

---

## Implementation Dependencies

### Sprint 0 Prerequisites (BLOCKING)

1. **Project Initialization** - `uv init --name dfir-assistant --python 3.11`
2. **VRAM Validation** - EPIC-001 must pass before other epics
3. **Evaluation Dataset** - Create golden Q&A set (EPIC-003)

### Epic Dependencies

```
EPIC-001 (VRAM) â”€â”€â–º ALL OTHER EPICS
    â”‚
    â”œâ”€â”€â–º EPIC-100 (Data Ingestion)
    â”‚         â”‚
    â”‚         â””â”€â”€â–º EPIC-101 (RAG Pipeline)
    â”‚                   â”‚
    â”‚                   â””â”€â”€â–º EPIC-102 (Response Generation)
    â”‚                             â”‚
    â”‚                             â””â”€â”€â–º EPIC-103 (User Interface)
    â”‚
    â”œâ”€â”€â–º EPIC-006 (PDF Processing) â”€â”€â–º EPIC-100
    â”‚
    â”œâ”€â”€â–º EPIC-002 (Command Validation) â”€â”€â–º EPIC-102
    â”‚
    â”œâ”€â”€â–º EPIC-005 (Retrieval Failure) â”€â”€â–º EPIC-101
    â”‚
    â”œâ”€â”€â–º EPIC-007 (Single Collection) â”€â”€â–º EPIC-100
    â”‚
    â”œâ”€â”€â–º EPIC-004 (Org Context) â”€â”€â–º EPIC-102
    â”‚
    â””â”€â”€â–º EPIC-003 (Evaluation) â”€â”€â–º All (regression testing)
```

---

---

## Step 2: Epic Design & Sprint Allocation

### Epic Grouping Validation

The PRD defines 11 epics in two categories. Let me validate the groupings:

#### Category A: Critical Review Epics (Risk Mitigation)
These epics address risks identified in the Critical Review phase.

| Epic | Purpose | Grouping Assessment |
|------|---------|---------------------|
| **EPIC-001** | VRAM Validation | âœ… Correct - Must be standalone, blocking |
| **EPIC-002** | Command Validation | âœ… Correct - Safety-critical, separate |
| **EPIC-003** | Evaluation Framework | âœ… Correct - Cross-cutting testing |
| **EPIC-004** | Org Context Maintenance | âœ… Correct - Feature extension |
| **EPIC-005** | Retrieval Failure Handling | âš ï¸ Consider merging into RAG Pipeline |
| **EPIC-006** | PDF Processing Quality | âœ… Correct - Data quality validation |
| **EPIC-007** | Single Collection Architecture | âš ï¸ Consider merging into Data Ingestion |

#### Category B: Feature Development Epics
These epics implement the core functionality.

| Epic | Purpose | Grouping Assessment |
|------|---------|---------------------|
| **EPIC-100** | Data Ingestion Pipeline | âœ… Correct - Foundation epic |
| **EPIC-101** | RAG Pipeline | âœ… Correct - Core retrieval |
| **EPIC-102** | Response Generation | âœ… Correct - LLM integration |
| **EPIC-103** | User Interface | âœ… Correct - Presentation layer |

### Recommended Epic Consolidation

Based on the grouping assessment, I recommend keeping the original 11 epics **unchanged** because:

1. **EPIC-005 (Retrieval Failure)** - Has distinct acceptance criteria around confidence scoring and "I don't know" responses that deserve separate tracking
2. **EPIC-007 (Single Collection)** - Has benchmark/validation stories that are distinct from ingestion implementation

**Verdict: Keep all 11 epics as designed in PRD v2.0** âœ…

---

### Dependency Graph (Validated)

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                              SPRINT 0 (BLOCKING)                                â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”‚
â”‚  â”‚  EPIC-001: VRAM Validation (8 pts)                                       â”‚    â”‚
â”‚  â”‚  âš ï¸ ALL other epics depend on this passing                               â”‚    â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                        â”‚
                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                    â”‚                                       â”‚
                    â–¼                                       â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚       SPRINT 1 (Foundation)       â”‚     â”‚      SPRINT 1 (Parallel)          â”‚
â”‚                                   â”‚     â”‚                                   â”‚
â”‚  EPIC-006: PDF Processing (8 pts) â”‚     â”‚  EPIC-003: Evaluation (13 pts)    â”‚
â”‚         Validates marker-pdf      â”‚     â”‚         Golden dataset creation   â”‚
â”‚                                   â”‚     â”‚                                   â”‚
â”‚  EPIC-007: Single Collection      â”‚     â”‚  EPIC-002: Command Validation     â”‚
â”‚         (5 pts) Schema design     â”‚     â”‚         (8 pts) Plugin registry   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                    â”‚                                       â”‚
                    â–¼                                       â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                       â”‚
â”‚        SPRINT 2 (Data)            â”‚                       â”‚
â”‚                                   â”‚                       â”‚
â”‚  EPIC-100: Data Ingestion (21 pts)â”‚                       â”‚
â”‚         PDF â†’ chunks â†’ vectors    â”‚                       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                       â”‚
                    â”‚                                       â”‚
                    â–¼                                       â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                       â”‚
â”‚       SPRINT 3 (Retrieval)        â”‚                       â”‚
â”‚                                   â”‚                       â”‚
â”‚  EPIC-101: RAG Pipeline (13 pts)  â”‚                       â”‚
â”‚         Hybrid search, rerank     â”‚â—„â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
â”‚                                   â”‚
â”‚  EPIC-005: Retrieval Failure      â”‚
â”‚         (8 pts) Confidence scoringâ”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                    â”‚
                    â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚      SPRINT 4 (Generation)        â”‚
â”‚                                   â”‚
â”‚  EPIC-102: Response Generation    â”‚
â”‚         (24 pts) LLM + Instructor â”‚
â”‚                                   â”‚
â”‚  EPIC-004: Org Context (5 pts)    â”‚
â”‚         Context injection         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                    â”‚
                    â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚        SPRINT 5 (UI)              â”‚
â”‚                                   â”‚
â”‚  EPIC-103: User Interface (11 pts)â”‚
â”‚         Gradio chat + streaming   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

### Sprint Allocation Plan

| Sprint | Epics | Points | Focus | Dependencies |
|--------|-------|--------|-------|--------------|
| **Sprint 0** | EPIC-001 | 8 | VRAM Validation (BLOCKING) | None |
| **Sprint 1** | EPIC-006, EPIC-007, EPIC-003, EPIC-002 | 34 | Foundation + Quality | Sprint 0 |
| **Sprint 2** | EPIC-100 | 21 | Data Ingestion | Sprint 1 |
| **Sprint 3** | EPIC-101, EPIC-005 | 21 | Retrieval System | Sprint 2 |
| **Sprint 4** | EPIC-102, EPIC-004 | 29 | Response Generation | Sprint 3 |
| **Sprint 5** | EPIC-103 | 11 | User Interface | Sprint 4 |
| **TOTAL** | 11 Epics | **124** | | |

**Velocity Assumption:** 20-25 points per sprint (2-week sprints)

---

### Epic Priority Matrix

| Priority | Epic | Points | Rationale |
|----------|------|--------|-----------|
| ğŸ”´ **P0 BLOCKING** | EPIC-001 | 8 | Must pass before any development |
| ğŸŸ  **P0 Foundation** | EPIC-006 | 8 | Data quality gates |
| ğŸŸ  **P0 Foundation** | EPIC-007 | 5 | Schema design |
| ğŸŸ  **P0 Foundation** | EPIC-002 | 8 | Command safety |
| ğŸŸ  **P0 Foundation** | EPIC-003 | 13 | Test infrastructure |
| ğŸŸ¡ **P0 Core** | EPIC-100 | 21 | Data pipeline |
| ğŸŸ¡ **P0 Core** | EPIC-101 | 13 | Search pipeline |
| ğŸŸ¡ **P0 Core** | EPIC-005 | 8 | Retrieval quality |
| ğŸŸ¢ **P0 Core** | EPIC-102 | 24 | LLM integration |
| ğŸ”µ **P1 Enhancement** | EPIC-004 | 5 | Org context |
| ğŸ”µ **P1 Enhancement** | EPIC-103 | 11 | User interface |

---

### Identified Gaps (Step 2 Analysis)

#### Missing Epics/Stories Identified

| Gap | Recommendation | Priority |
|-----|----------------|----------|
| **Project Setup Story** | Add to Sprint 0: uv init, directory structure | P0 |
| **CI/CD Pipeline Story** | Add to EPIC-003 or new EPIC | P1 |
| **Documentation Story** | Add to EPIC-103 or final sprint | P1 |
| **Deployment Story** | Add systemd service setup | P1 |

#### Recommended Additional Stories

**Sprint 0 Addition:**
```
STORY-000: Project Initialization
- uv init --name dfir-assistant --python 3.11
- Create directory structure per architecture
- Add pyproject.toml with dependencies
- Verify air-gap dependency export works
Points: 2
```

**Sprint 5 Addition:**
```
STORY-104: Deployment Configuration
- Create systemd service file
- Write deployment guide
- Test server restart recovery
Points: 3
```

---

### Requirements Coverage Check

| Requirement | Covered By Epic | Status |
|-------------|-----------------|--------|
| FR-001: Knowledge Q&A | EPIC-101, EPIC-102 | âœ… |
| FR-002: Anomaly Explanation | EPIC-102 (AnomalyResponse) | âœ… |
| FR-003: Procedural Guidance | EPIC-102 (ProcedureResponse) | âœ… |
| FR-004: Org Context | EPIC-004, EPIC-102 | âœ… |
| FR-005: Multi-Turn | EPIC-102, EPIC-103 | âœ… |
| NFR-PERF: Performance | EPIC-101, EPIC-102 | âœ… |
| NFR-SEC: Security | All (air-gap design) | âœ… |
| NFR-SCALE: Scalability | EPIC-007, EPIC-100 | âœ… |
| NFR-AVAIL: Availability | EPIC-103 (systemd) | âœ… |
| NFR-VRAM: VRAM Budget | EPIC-001 | âœ… |
| NFR-TRUST: Trust | EPIC-002, EPIC-005 | âœ… |

**Coverage: 100%** âœ…

---

### Epic Design Summary

**Total Epics:** 11 (unchanged from PRD)
**Total Stories:** 37 pre-defined + 2 recommended additions = **39 stories**
**Total Points:** 124 + 5 = **129 points**
**Estimated Sprints:** 6 (including Sprint 0)
**Estimated Duration:** 12 weeks (6 Ã— 2-week sprints)

---

## Next Steps

**Step 3: Create Stories**
- Expand each story with detailed acceptance criteria
- Add technical requirements and dependencies
- Confirm estimates
- Add the 2 recommended new stories

**Step 4: Final Validation**
- Verify all requirements covered
- Check story dependencies
- Confirm implementation readiness

---

*Step 2 completed: Epic design validated, sprint allocation defined, 100% requirements coverage confirmed.*

---

## Step 4: Final Validation

### Requirements to Stories Traceability

| Requirement | Stories | Coverage |
|-------------|---------|----------|
| **FR-001: Knowledge Q&A** | FD-011, FD-012, FD-013, FD-020, FD-024 | âœ… 100% |
| **FR-002: Anomaly Explanation** | FD-022, FD-023 | âœ… 100% |
| **FR-003: Procedural Guidance** | FD-022, FD-025 | âœ… 100% |
| **FR-004: Organization Context** | CR-011, CR-012, CR-013 | âœ… 100% |
| **FR-005: Multi-Turn Conversations** | FD-030 (session state) | âœ… 100% |
| **NFR-PERF: Performance** | FD-010, FD-011, FD-031 | âœ… 100% |
| **NFR-SEC: Security** | All (air-gap design) | âœ… 100% |
| **NFR-VRAM: VRAM Budget** | CR-001, CR-002, CR-003 | âœ… 100% |
| **NFR-TRUST: Trust** | CR-004, CR-005, CR-006, CR-014, CR-015 | âœ… 100% |

### Story Dependencies Validation

```
Sprint 0 (BLOCKING)
    STORY-000 â”€â”€â–º All subsequent stories
    STORY-CR-001 â”€â”€â–º STORY-CR-002 â”€â”€â–º STORY-CR-003
    
Sprint 1 (Foundation)
    STORY-CR-017 â”€â”€â–º STORY-CR-018 â”€â”€â–º STORY-CR-019
    STORY-CR-020 â”€â”€â–º STORY-CR-021 (conditional)
    STORY-CR-007 â”€â”€â–º STORY-CR-008 â”€â”€â–º STORY-CR-009 â”€â”€â–º STORY-CR-010
    STORY-CR-004 â”€â”€â–º STORY-CR-005 â”€â”€â–º STORY-CR-006
    
Sprint 2 (Data Ingestion)
    STORY-FD-001 â”€â”€â–º STORY-FD-002 â”€â”€â–º STORY-FD-003 â”€â”€â–º STORY-FD-004 â”€â”€â–º STORY-FD-005
    
Sprint 3 (Retrieval)
    STORY-FD-010 â”€â”€â–º STORY-FD-011 â”€â”€â–º STORY-FD-012 â”€â”€â–º STORY-FD-013
    STORY-CR-014 â”€â”€â–º STORY-CR-015, STORY-CR-016
    
Sprint 4 (Generation)
    STORY-FD-020 â”€â”€â–º STORY-FD-021 â”€â”€â–º STORY-FD-022 â”€â”€â–º STORY-FD-023, FD-024, FD-025
    STORY-CR-011 â”€â”€â–º STORY-CR-012 â”€â”€â–º STORY-CR-013
    
Sprint 5 (UI)
    STORY-FD-030 â”€â”€â–º STORY-FD-031, FD-032, FD-033
    STORY-104 (can parallel)
```

**Dependency Chain Length:** 5 sprints (critical path)
**No Circular Dependencies:** âœ… Verified
**All Blockers Identified:** âœ… EPIC-001 clearly marked

### Acceptance Criteria Quality Check

| Criterion | Standard | Result |
|-----------|----------|--------|
| **Testable** | Each AC can be verified | âœ… All use Given/When/Then |
| **Specific** | No ambiguous terms | âœ… Concrete values provided |
| **Independent** | Stories can be tested alone | âœ… With mocked dependencies |
| **Valuable** | Each delivers user/dev value | âœ… Clear benefit stated |
| **Estimable** | Points assigned | âœ… All stories estimated |

### Implementation Readiness Checklist

- [x] All 5 FRs covered by stories
- [x] All NFRs addressed in architecture + stories
- [x] BLOCKING stories clearly identified (Sprint 0)
- [x] Story dependencies mapped
- [x] Points estimated (129 total)
- [x] Sprint allocation defined (6 sprints)
- [x] Technical notes reference architecture
- [x] File paths specified for all new components
- [x] External dependencies identified (Ollama, Qdrant, marker-pdf)
- [x] Risk mitigation stories included (EPIC-001 through EPIC-007)

### Validation Summary

| Metric | Value | Status |
|--------|-------|--------|
| **Total Stories** | 39 | âœ… |
| **Total Points** | 129 | âœ… |
| **Requirements Coverage** | 100% | âœ… |
| **Dependency Validation** | No cycles | âœ… |
| **Acceptance Criteria** | All testable | âœ… |
| **Sprint Allocation** | 6 sprints | âœ… |

---

## Workflow Completion

### Create Epics and Stories Workflow: COMPLETE âœ…

**Steps Completed:**
1. âœ… Step 1: Requirements Extraction
2. âœ… Step 2: Epic Design
3. âœ… Step 3: Story Creation
4. âœ… Step 4: Final Validation

### Output Documents

| Document | Location | Purpose |
|----------|----------|---------|
| **epics.md** | `_bmad-output/planning-artifacts/epics.md` | Epic definitions, sprint allocation, requirements mapping |
| **stories.md** | `_bmad-output/planning-artifacts/stories.md` | Detailed stories with acceptance criteria |

### Next Phase: Implementation

**Sprint 0 Ready to Start:**
1. STORY-000: Project Initialization (2 pts)
2. STORY-CR-001: VRAM Usage Validation (3 pts)
3. STORY-CR-002: Fallback LLM Configuration (3 pts)
4. STORY-CR-003: VRAM Monitoring (2 pts)

**First Implementation Task:**
```bash
# Initialize project
uv init --name dfir-assistant --python 3.11
uv add gradio qdrant-client instructor httpx marker-pdf pydantic pyyaml rich
uv sync

# Run VRAM validation
uv run python scripts/validate_vram.py
```

---

*Create Epics and Stories workflow completed. Project ready for Sprint 0 implementation.*
